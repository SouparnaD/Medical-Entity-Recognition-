{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "cadec_twitter_bilstmCNNcrf_.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYd8W44RDZIk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "# dataset_path = '/content/drive/My Drive/Colab Notebooks/MER/model_trial/dataset/CADEC.csv'\n",
        "dataset_path_twitter = '/content/gdrive/My Drive/updated_annotated_data.csv'\n",
        "# dataset_path_twitter = '/content/drive/My Drive/Colab Notebooks/MER/model_trial/dataset/twitter_521.csv'\n",
        "BATCH_SIZE = 128  # Number of examples used in each iteration\n",
        "EPOCHS = 100 #Number of passes through entire dataset\n",
        "MAX_LEN = 35  # Max length of review (in words)\n",
        "EMBEDDING = 200# Dimension of word embedding vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzXTEgRQDZI2",
        "colab_type": "code",
        "outputId": "a2cdaeff-19a3-45a9-c89d-7623c0c3ab17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "source": [
        "data = pd.read_csv(dataset_path_twitter, names=['sec_no', 'word', 'label'], header=0)\n",
        "# data = pd.read_csv(dataset_path)\n",
        "\n",
        "# data = data.drop(['Document ID'], axis=1)\n",
        "\n",
        "# Adding some of the twitter data in the cadec dataset to train better for the twitter data\n",
        "# data = data.append(data_twitter[0:5991], ignore_index=True)\n",
        "# # Remaining twitter data is for testing\n",
        "# data_twitter = data_twitter[5991:]\n",
        "# print(data_twitter.shape)\n",
        "\n",
        "data = data.fillna(method=\"ffill\")\n",
        "# data_twitter = data_twitter.fillna(method=\"ffill\")\n",
        "\n",
        "print(\"Number of sentences: \", len(data.groupby(['sec_no'])))\n",
        "# print(\"Number of sentences in twitter : \", len(data_twitter.groupby(['Sentence No'])))\n",
        "\n",
        "\n",
        "words = list(set(data[\"word\"].values))\n",
        "n_words = len(words)\n",
        "print(\"Number of words in the dataset: \", n_words)\n",
        "# words_twitter = list(set(data_twitter[\"Word\"].values))\n",
        "# n_words_twitter = len(words_twitter)\n",
        "# print(\"Number of words in the dataset: \", n_words_twitter)\n",
        "\n",
        "tags = list(set(data[\"label\"].values))\n",
        "print(\"Tags:\", tags)\n",
        "n_tags = len(tags)\n",
        "print(\"Number of Labels: \", n_tags)\n",
        "\n",
        "print(\"What the dataset looks like:\")\n",
        "# Show the first 10 rows\n",
        "data['label'].value_counts()\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of sentences:  342204\n",
            "Number of words in the dataset:  264290\n",
            "Tags: ['B-Symptom', 'O', 'I-Symptom']\n",
            "Number of Labels:  3\n",
            "What the dataset looks like:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "O            5034983\n",
              "B-Symptom     352543\n",
              "I-Symptom       5155\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmYBWv2zDZJF",
        "colab_type": "code",
        "outputId": "cd25b51c-e765-4908-bb7f-922b4349d36f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "from random import shuffle\n",
        "import random\n",
        "class SentenceGetter(object):\n",
        "    \"\"\"Class to Get the sentence in this format:\n",
        "    [(Token_1, Tag_1), ..., (Token_n, Tag_1)]\"\"\"\n",
        "    def __init__(self, data):\n",
        "        \"\"\"Args:\n",
        "            data is the pandas.DataFrame which contains the above dataset\"\"\"\n",
        "        self.n_sent = 1\n",
        "        self.data = data\n",
        "        self.empty = False\n",
        "        agg_func = lambda s: [(w, t) for w, t in zip(s[\"word\"].values.tolist(),\n",
        "                                                           s[\"label\"].values.tolist())]\n",
        "        self.grouped = self.data.groupby(\"sec_no\").apply(agg_func)\n",
        "        self.sentences = [s for s in self.grouped]\n",
        "    \n",
        "    def get_next(self):\n",
        "        \"\"\"Return one sentence\"\"\"\n",
        "        try:\n",
        "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
        "            self.n_sent += 1\n",
        "            return s\n",
        "        except:\n",
        "            return None\n",
        "        \n",
        "getter = SentenceGetter(data)\n",
        "# getter_twitter = SentenceGetter(data_twitter)\n",
        "sent = getter.get_next()# Get all the sentences\n",
        "sentences = getter.sentences\n",
        "# sentences_twitter = getter_twitter.sentences\n",
        "\n",
        "\n",
        "# print(sentences_twitter)\n",
        "# Shuffling the cadec and twitter dataset for better training\n",
        "sentences = random.sample(sentences, len(sentences))\n",
        "print(len(sentences))\n",
        "sentences\n",
        "\n",
        "# Plot sentence by lenght\n",
        "plt.hist([len(s) for s in sentences], bins=50)\n",
        "plt.title('Token per sentence')\n",
        "plt.xlabel('Len (number of token)')\n",
        "plt.ylabel('# samples')\n",
        "plt.show()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "342204\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEWCAYAAACnlKo3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nPoQwAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "o_lT35CyDZJS",
        "colab_type": "code",
        "outputId": "1d7fc310-17d0-461c-caab-674c94b806ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "\n",
        "X = [[w[0]for w in s] for s in sentences]\n",
        "new_X = []\n",
        "for seq in X:\n",
        "    new_seq = []\n",
        "    for i in range(MAX_LEN):\n",
        "        try:\n",
        "            new_seq.append(seq[i])\n",
        "        except:\n",
        "            new_seq.append(\"PAD\")\n",
        "    new_X.append(new_seq)\n",
        "\n",
        "new_X[15]\n",
        "\n",
        "# Mapping the string data to the numbers\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "tags2index = {t:i for i,t in enumerate(tags)}\n",
        "y = [[tags2index[w[1]] for w in s] for s in sentences]\n",
        "y = pad_sequences(maxlen=MAX_LEN, sequences=y, padding=\"post\", value=tags2index[\"O\"])\n",
        "y[15]\n",
        "\n",
        "#------------------------------------------------------------------- with twitter data\n",
        "# # Vocabulary Key:word -> Value:token_index\n",
        "# # The first 2 entries are reserved for PAD and UNK\n",
        "# word2idx = {w: i + 2 for i, w in enumerate(words)}\n",
        "# word2idx[\"UNK\"] = 1 # Unknown words\n",
        "# word2idx[\"PAD\"] = 0 # Padding\n",
        "# word2idx\n",
        "# word2idx_twitter = {w: i + 2 for i, w in enumerate(words_twitter)}\n",
        "# word2idx_twitter[\"UNK\"] = 1 # Unknown words\n",
        "# word2idx_twitter[\"PAD\"] = 0 # Padding\n",
        "# word2idx_twitter\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# # Vocabulary Key:token_index -> Value:word\n",
        "# idx2word_twitter = {i: w for w, i in word2idx_twitter.items()}\n",
        "# idx2word_twitter\n",
        "# idx2word = {i: w for w, i in word2idx.items()}\n",
        "# idx2word\n",
        "\n",
        "# # Vocabulary Key:Label/Tag -> Value:tag_index\n",
        "# # The first entry is reserved for PAD\n",
        "# tag2idx = {t: i+1 for i, t in enumerate(tags)}\n",
        "# tag2idx[\"PAD\"] = 0\n",
        "# tag2idx\n",
        "\n",
        "\n",
        "# # Vocabulary Key:tag_index -> Value:Label/Tag\n",
        "# idx2tag = {i: w for w, i in tag2idx.items()}\n",
        "# idx2tag\n",
        "\n",
        "\n",
        "# print(\"The word Drugs is identified by the index: {}\".format(word2idx[\"Drug\"]))\n",
        "# print(\"The labels B-Symptom(which defines Symptom related Enitities) is identified by the index: {}\".format(tag2idx[\"B-Symptom\"]))\n",
        "\n",
        "# from keras.preprocessing.sequence import pad_sequences\n",
        "# # Convert each sentence from list of Token to list of word_index\n",
        "\n",
        "# X = [[word2idx[w[0]] for w in s] for s in sentences]\n",
        "# # Padding each sentence to have the same lenght\n",
        "# X = pad_sequences(maxlen=MAX_LEN, sequences=X, padding=\"post\", value=word2idx[\"PAD\"])\n",
        "\n",
        "# X_twitter = [[word2idx_twitter[w[0]] for w in s] for s in sentences_twitter]\n",
        "# # Padding each sentence to have the same lenght\n",
        "# X_twitter = pad_sequences(maxlen=MAX_LEN, sequences=X_twitter, padding=\"post\", value=word2idx_twitter[\"PAD\"])\n",
        "\n",
        "\n",
        "# # Convert Tag/Label to tag_index\n",
        "# y = [[tag2idx[w[1]] for w in s] for s in sentences]\n",
        "# # Padding each sentence to have the same length\n",
        "# y = pad_sequences(maxlen=MAX_LEN, sequences=y, padding=\"post\", value=tag2idx[\"PAD\"])\n",
        "# from keras.utils import to_categorical\n",
        "# # One-Hot encode\n",
        "# y = [to_categorical(i, num_classes=n_tags+1) for i in y]  # n_tags+1(PAD)\n",
        "\n",
        "\n",
        "# y_twitter = [[tag2idx[w[1]] for w in s] for s in sentences_twitter]\n",
        "# # Padding each sentence to have the same length\n",
        "# y_twitter = pad_sequences(maxlen=MAX_LEN, sequences=y_twitter, padding=\"post\", value=tag2idx[\"PAD\"])\n",
        "# from keras.utils import to_categorical\n",
        "# # One-Hot encode\n",
        "# y_twitter = [to_categorical(i, num_classes=n_tags+1) for i in y_twitter]  # n_tags+1(PAD)\n",
        "\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# # X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.1)  #this was used when CADEC was used for trraining, testing both\n",
        "\n",
        "# X_tr, X_te = X, X_twitter\n",
        "# y_tr, y_te = y, y_twitter\n",
        "\n",
        "\n",
        "# X_tr.shape, X_te.shape, np.array(y_tr).shape, np.array(y_te).shape\n",
        "\n",
        "\n",
        "# # print(\" sentence is : \")\n",
        "# # (print(idx2word_twitter[word]) for word in sentences_twitter)\n",
        "\n",
        "# print('Raw Sample: ', ' '.join([w[0] for w in sentences[0]]))\n",
        "# print('Raw Label: ', ' '.join([w[1] for w in sentences[0]]))\n",
        "# print('Raw Sample: ', ' '.join([w[0] for w in sentences_twitter[0]]))\n",
        "# print('Raw Label: ', ' '.join([w[1] for w in sentences_twitter[0]]))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7idoPxjQDZJd",
        "colab_type": "code",
        "outputId": "102d980c-f3ba-4ab9-b644-617bac167b24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from keras import backend as K\n",
        "\n",
        "\n",
        "\n",
        "# new_X = new_X[:1000]\n",
        "# y = y[:1000]\n",
        "\n",
        "X_tr, X_te, y_tr, y_te = train_test_split(new_X, y, test_size=0.2, random_state=2018)\n",
        "print(np.array(X_tr).shape)\n",
        "print(np.array(X_te).shape)\n",
        "\n",
        "sess = tf.Session()\n",
        "K.set_session(sess)\n",
        "elmo_model = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=True)\n",
        "sess.run(tf.global_variables_initializer())\n",
        "sess.run(tf.tables_initializer())\n",
        "\n",
        "BATCH_SIZE = 256\n",
        "def ElmoEmbedding(x):\n",
        "    return elmo_model(inputs={\"tokens\": tf.squeeze(tf.cast(x,    tf.string)),\"sequence_len\": tf.constant(BATCH_SIZE*[MAX_LEN])\n",
        "                     },\n",
        "                      signature=\"tokens\",\n",
        "                      as_dict=True)[\"elmo\"]\n",
        "\n",
        "from keras.models import Model, Input\n",
        "from keras.layers.merge import add\n",
        "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Lambda\n",
        "input_text = Input(shape=(MAX_LEN,), dtype=tf.string)\n",
        "embedding = Lambda(ElmoEmbedding, output_shape=(MAX_LEN, 1024))(input_text)\n",
        "x = Bidirectional(LSTM(units=512, return_sequences=True,\n",
        "                       recurrent_dropout=0.2, dropout=0.2))(embedding)\n",
        "x_rnn = Bidirectional(LSTM(units=512, return_sequences=True,\n",
        "                           recurrent_dropout=0.2, dropout=0.2))(x)\n",
        "x = add([x, x_rnn])  # residual connection to the first biLSTM\n",
        "out = TimeDistributed(Dense(n_tags, activation=\"softmax\"))(x)\n",
        "model = Model(input_text, out)\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "\n",
        "# --------------------------------------------------------------- with twitter data\n",
        "# from keras.models import Model, Input\n",
        "# from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
        "# from keras_contrib.layers import CRF\n",
        "\n",
        "# # Model definition\n",
        "# input = Input(shape=(MAX_LEN,))\n",
        "# input\n",
        "# model = Embedding(input_dim=n_words+2, output_dim=EMBEDDING, # n_words + 2 (PAD & UNK)\n",
        "#                   input_length=MAX_LEN, mask_zero=True)(input)  # default: 20-dim embedding\n",
        "# model = Bidirectional(LSTM(units=50, return_sequences=True,\n",
        "#                            recurrent_dropout=0.1))(model)  # variational biLSTM\n",
        "# model = TimeDistributed(Dense(50, activation=\"relu\"))(model)  # a dense layer as suggested by neuralNer\n",
        "# crf = CRF(n_tags+1)  # CRF layer, n_tags+1(PAD)\n",
        "# out = crf(model)  # output\n",
        "\n",
        "# model = Model(input, out)\n",
        "# model.compile(optimizer=\"rmsprop\", loss=crf.loss_function, metrics=[crf.accuracy])\n",
        "\n",
        "\n",
        "# model.summary()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(273763, 35)\n",
            "(68441, 35)\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 35)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2 (Lambda)               (None, 35, 1024)     0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_3 (Bidirectional) (None, 35, 1024)     6295552     lambda_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_4 (Bidirectional) (None, 35, 1024)     6295552     bidirectional_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 35, 1024)     0           bidirectional_3[0][0]            \n",
            "                                                                 bidirectional_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_2 (TimeDistrib (None, 35, 3)        3075        add_2[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 12,594,179\n",
            "Trainable params: 12,594,179\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LOwH4Ea7LLr",
        "colab_type": "code",
        "outputId": "af372342-e924-4786-ebc9-4cf0f6a9b33e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "source": [
        "l = int(len(X_tr)/BATCH_SIZE)\n",
        "print(BATCH_SIZE)\n",
        "print(l)\n",
        "l = l-10\n",
        "print(l)\n",
        "l = l*BATCH_SIZE\n",
        "# X_tr, X_val = X_tr[:28*BATCH_SIZE], X_tr[-3*BATCH_SIZE:]\n",
        "# y_tr, y_val = y_tr[:28*BATCH_SIZE], y_tr[-3*BATCH_SIZE:]\n",
        "X_trn, X_valn = X_tr[:l], X_tr[l:l+BATCH_SIZE*10]\n",
        "y_trn, y_valn = y_tr[:l], y_tr[l:l+BATCH_SIZE*10]\n",
        "print(len(X_trn), len(X_valn))\n",
        "y_trn = y_trn.reshape(y_trn.shape[0], y_trn.shape[1], 1)\n",
        "y_valn = y_valn.reshape(y_valn.shape[0], y_valn.shape[1], 1)\n",
        "\n",
        "history = model.fit(np.array(X_trn), y_trn, validation_data = (np.array(X_valn), y_valn) ,batch_size=BATCH_SIZE, epochs=3, verbose=1)\n",
        "\n",
        "\n",
        "#--------------------------------------------------------------- withh twitter data\n",
        "# # history = model.fit(X_tr, np.array(y_tr), batch_size=BATCH_SIZE, epochs=EPOCHS,validation_split=0.1, verbose=2) #this was used when CADEC was used for training, testing both\n",
        "# history = model.fit(X_tr, np.array(y_tr), batch_size=BATCH_SIZE, epochs=EPOCHS,validation_split=0.0, verbose=2)\n",
        "\n",
        "# # Eval\n",
        "# pred_cat = model.predict(X_te)\n",
        "# print(pred_cat.shape)\n",
        "# pred = np.argmax(pred_cat, axis=-1)\n",
        "# y_te_true = np.argmax(y_te, -1)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "256\n",
            "1069\n",
            "1059\n",
            "271104 2560\n",
            "Train on 271104 samples, validate on 2560 samples\n",
            "Epoch 1/3\n",
            "271104/271104 [==============================] - 2432s 9ms/step - loss: 0.0117 - acc: 0.9961 - val_loss: 0.0038 - val_acc: 0.9987\n",
            "Epoch 2/3\n",
            "271104/271104 [==============================] - 2430s 9ms/step - loss: 0.0032 - acc: 0.9989 - val_loss: 0.0028 - val_acc: 0.9992\n",
            "Epoch 3/3\n",
            "271104/271104 [==============================] - 2426s 9ms/step - loss: 0.0021 - acc: 0.9993 - val_loss: 0.0020 - val_acc: 0.9994\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nFM0WunDmp1",
        "colab_type": "code",
        "outputId": "86c92986-205f-4f7d-90e8-4363078697fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "# !pip install seqeval\n",
        "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n",
        "X_tes = np.array(X_te[:200*256])\n",
        "print(np.array(X_trn).shape)\n",
        "print(np.array(X_tes).shape)\n",
        "print(np.array(X_te).shape)\n",
        "test_pred = model.predict(np.array(X_tes), verbose=1, batch_size=256)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(271104, 35)\n",
            "(51200, 35)\n",
            "(68441, 35)\n",
            "51200/51200 [==============================] - 372s 7ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KH7WpCU4XGnb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "4940524c-fd50-4d7e-e054-792521580f38"
      },
      "source": [
        "test_pred.shape"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(51200, 35, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjFbAjwn93Dz",
        "colab_type": "code",
        "outputId": "997d3ad0-a175-49b2-c327-6a7881be2536",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        }
      },
      "source": [
        "idx2tag = {i: w for w, i in tags2index.items()}\n",
        "\n",
        "\n",
        "def pred2label(pred):\n",
        "    out = []\n",
        "    for pred_i in pred:\n",
        "        out_i = []\n",
        "        for p in pred_i:\n",
        "            p_i = np.argmax(p)\n",
        "            out_i.append(idx2tag[p_i].replace(\"PADword\", \"O\"))\n",
        "        out.append(out_i)\n",
        "    return out\n",
        "    \n",
        "def test2label(pred):\n",
        "    out = []\n",
        "    for pred_i in pred:\n",
        "        out_i = []\n",
        "        for p in pred_i:\n",
        "            out_i.append(idx2tag[p].replace(\"PADword\", \"O\"))\n",
        "        out.append(out_i)\n",
        "    return out\n",
        "    \n",
        "pred_labels = pred2label(test_pred)\n",
        "\n",
        "test_labels = test2label(y_te[:200*256])\n",
        "print(classification_report(test_labels, pred_labels))\n",
        "print(np.array(pred_labels).shape)\n",
        "print(np.array(test_labels).shape)\n",
        "\n",
        "count = 0\n",
        "total = 0\n",
        "for i in range(len(test_labels)):\n",
        "  if test_labels[i] == pred_labels[i]:\n",
        "    count += 1\n",
        "  total += 1\n",
        "print(\" accuracy : \",count/total)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "           precision    recall  f1-score   support\n",
            "\n",
            "  Symptom       0.98      0.99      0.99     52744\n",
            "\n",
            "micro avg       0.98      0.99      0.99     52744\n",
            "macro avg       0.98      0.99      0.99     52744\n",
            "\n",
            "(51200, 35)\n",
            "(51200, 35)\n",
            " accuracy :  0.9801953125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUOnaUcQXctD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "outputId": "75358efa-e5d4-409f-ba49-af2b4dee52c3"
      },
      "source": [
        "# !pip install sklearn_crfsuite\n",
        "from sklearn_crfsuite.metrics import flat_classification_report\n",
        "\n",
        "print(flat_classification_report(test_labels, pred_labels))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   B-Symptom       0.98      0.99      0.99     52744\n",
            "   I-Symptom       0.93      0.89      0.91       754\n",
            "           O       1.00      1.00      1.00   1738502\n",
            "\n",
            "    accuracy                           1.00   1792000\n",
            "   macro avg       0.97      0.96      0.97   1792000\n",
            "weighted avg       1.00      1.00      1.00   1792000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9zEUZi7hSPO",
        "colab_type": "code",
        "outputId": "cd2728d3-efa0-4cff-c3b9-2284e4dc4d73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUzrFgO6hTQs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install git+https://www.github.com/keras-team/keras-contrib.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSWvgJqf5CSD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install tensorflow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "992VTd9l5a8M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install keras==2.2.4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_r0nZxrx6XoS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install sklearn-crfsuite"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSU7bI86ERV2",
        "colab_type": "code",
        "outputId": "68e35a87-9535-434e-e3b6-d2ca1b8ac27b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        }
      },
      "source": [
        "# !pip install seqeval"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting seqeval\n",
            "  Downloading https://files.pythonhosted.org/packages/34/91/068aca8d60ce56dd9ba4506850e876aba5e66a6f2f29aa223224b50df0de/seqeval-0.0.12.tar.gz\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from seqeval) (1.17.3)\n",
            "Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.6/dist-packages (from seqeval) (2.2.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (2.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.1.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.3.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.0.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (3.13)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.12.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-0.0.12-cp36-none-any.whl size=7424 sha256=042186aa1e059b07de5997b09b0fc3358c1046926e86316fc0323c6034b666a5\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/32/0a/df3b340a82583566975377d65e724895b3fad101a3fb729f68\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-0.0.12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxJlRd0pESF2",
        "colab_type": "code",
        "outputId": "8dd66064-0d4a-400a-cb92-af1039190972",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "source": [
        "!pip install sklearn_crfsuite"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sklearn_crfsuite\n",
            "  Downloading https://files.pythonhosted.org/packages/25/74/5b7befa513482e6dee1f3dd68171a6c9dfc14c0eaa00f885ffeba54fe9b0/sklearn_crfsuite-0.3.6-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (1.12.0)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (4.28.1)\n",
            "Collecting python-crfsuite>=0.8.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2f/86/cfcd71edca9d25d3d331209a20f6314b6f3f134c29478f90559cee9ce091/python_crfsuite-0.9.6-cp36-cp36m-manylinux1_x86_64.whl (754kB)\n",
            "\u001b[K     |████████████████████████████████| 757kB 7.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (0.8.5)\n",
            "Installing collected packages: python-crfsuite, sklearn-crfsuite\n",
            "Successfully installed python-crfsuite-0.9.6 sklearn-crfsuite-0.3.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYrdv__6EgE3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "a0923b02-eb35-4ddc-b151-25142fd72c27"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DREAwr5wgFFi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}